---
phase: 10-algorithm-and-validation-tests
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - src/orchestrator/dag.test.ts
  - src/context/tracker.test.ts
autonomous: true

must_haves:
  truths:
    - 'DAGOrchestrator tests verify linear, diamond, and parallel execution shapes produce correct step ordering'
    - 'DAGOrchestrator cycle detection throws OrchestratorError with code ORCHESTRATOR_CYCLE'
    - 'DAGOrchestrator missing dependency throws OrchestratorError with code ORCHESTRATOR_MISSING_DEP'
    - 'DAGOrchestrator skip propagation skips transitive dependents in 3+ step chains (not just direct dependents)'
    - 'DAGOrchestrator event hooks (onStepStart, onStepComplete, onStepFail) are called with correct arguments'
    - 'TokenUsageTracker tests confirm stateful accounting is correct across 0, 1, and 3 rounds'
    - 'TokenUsageTracker.estimateCost() uses correct model pricing with cache read and cache creation contributions'
    - 'TokenUsageTracker.getRoundCacheSavings() returns null when no cache data and correct savings when present'
    - "TokenUsageTracker.toSummary() returns 'No rounds recorded.' for empty tracker and contains per-round lines for populated tracker"
  artifacts:
    - path: 'src/orchestrator/dag.test.ts'
      provides: 'DAGOrchestrator unit tests'
    - path: 'src/context/tracker.test.ts'
      provides: 'TokenUsageTracker unit tests'
  key_links:
    - from: 'src/orchestrator/dag.test.ts'
      to: 'src/orchestrator/dag.ts'
      via: 'import { DAGOrchestrator }'
    - from: 'src/orchestrator/dag.test.ts'
      to: 'src/utils/errors.ts'
      via: 'import { OrchestratorError }'
    - from: 'src/context/tracker.test.ts'
      to: 'src/context/tracker.ts'
      via: 'import { TokenUsageTracker }'
---

<objective>
Write unit tests for `DAGOrchestrator` and `TokenUsageTracker` — the codebase's reactive execution engine (step ordering, cycle detection, skip propagation) and its stateful token accounting system (multi-round accumulation, cost estimation, cache savings).

Purpose: Cover DAG orchestration edge cases (cycles, transitive skip propagation, event hooks) and token tracker state transitions (accumulation, cost formulas, summary formatting) so regressions in pipeline execution and cost reporting are caught immediately.

Output: Two test files (`dag.test.ts`, `tracker.test.ts`) with all critical behaviors verified.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/10-algorithm-and-validation-tests/10-RESEARCH.md

@src/orchestrator/dag.ts
@src/orchestrator/types.ts
@src/domain/types.ts
@src/context/tracker.ts
@src/context/types.ts
@src/utils/errors.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Write DAGOrchestrator tests</name>
  <files>src/orchestrator/dag.test.ts</files>
  <action>
Create `src/orchestrator/dag.test.ts` with comprehensive tests for `DAGOrchestrator`.

**Imports:** `DAGOrchestrator` from `./dag.js`, `OrchestratorError` from `../utils/errors.js`. Types: `StepDefinition` from `./types.js`.

**Local helper:**

- `mkStep(id: string, deps: string[], executeFn?: () => Promise<unknown>, onSkip?: () => void): StepDefinition` — Creates a step with `name` defaulting to `id.toUpperCase()`, `execute` defaulting to `async () => {}`, and optional `onSkip`.
- For execution order tracking, use a shared `log: string[]` array where each step's execute pushes its id.

**IMPORTANT:** Create a new `DAGOrchestrator()` instance per test — the internal step Map is stateful and would cause cross-test pollution if reused.

**Test scenarios (describe block "DAGOrchestrator"):**

**Execution ordering (describe "step ordering"):**

1. **Single step, no deps** — One step with no deps. Assert `results.get('a')?.status === 'completed'`
2. **Linear A->B->C** — Three steps chained. Assert `log` is `['a', 'b', 'c']` in exact order
3. **Diamond A->B, A->C, B+C->D** — Assert `log[0] === 'a'`, `log[log.length - 1] === 'd'`, all four steps completed. Do NOT assert B vs C ordering (non-deterministic parallel)
4. **Two independent steps (parallel roots)** — Two steps with no deps. Assert both `status === 'completed'`. Do NOT assert execution order between them
5. **Wide fan-out A->{B,C,D,E}** — A has no deps, B/C/D/E all depend on A. Assert A executes first, all 5 complete

**Validation errors (describe "validation"):**

6. **Cycle A->B->A** — `execute()` rejects with `OrchestratorError`, catch and inspect `error.code === 'ORCHESTRATOR_CYCLE'`
7. **Larger cycle A->B->C->A** — Same cycle detection but with 3-node cycle. Assert `OrchestratorError` with `code === 'ORCHESTRATOR_CYCLE'`
8. **Missing dependency reference** — Step B depends on 'nonexistent'. Assert `execute()` rejects with `OrchestratorError`, `code === 'ORCHESTRATOR_MISSING_DEP'`
9. **Duplicate step id** — Call `addStep` twice with same id. Assert synchronous `throw Error` with message containing the step id

**Failure and skip propagation (describe "skip propagation"):**

10. **Direct failure: B fails, C (depends on B) is skipped** — B throws Error. Assert `b.status === 'failed'`, `c.status === 'skipped'`
11. **Fan-out failure: A fails, B and C (both depend on A) are skipped** — A throws. Assert both B and C `status === 'skipped'`
12. **Transitive skip (3-step chain): A->B->C, A fails** — A throws. Assert B skipped, C skipped (tests recursive skipDependents). This is the critical multi-hop test from Pitfall 3 in research.
13. **Diamond failure: A->B, A->C, B+C->D. B fails** — B throws, C succeeds. Assert D is skipped (because B failed, even though C completed). This tests the `anyDepFailed` check in `checkDependents`.
14. **Independent branch continues: A->B(fail), C->D(success)** — B fails, but C->D is independent. Assert D `status === 'completed'` despite B failing
15. **onSkip callback invoked** — Step C has an `onSkip` vi.fn(). A fails, B depends on A, C depends on B. Assert C's `onSkip` was called exactly once

**Event hooks (describe "events"):**

16. **onStepStart called for each step** — Create DAGOrchestrator with `{ onStepStart: vi.fn() }`. Run 2-step chain. Assert `onStepStart` called twice with correct `(stepId, name)` args
17. **onStepComplete called on success** — `onStepComplete: vi.fn()`. Assert called with result object containing `status: 'completed'` and correct `stepId`
18. **onStepFail called on failure** — `onStepFail: vi.fn()`. Step throws. Assert called with result containing `status: 'failed'` and `error` property

**Step result data (describe "results"):**

19. **Completed step has duration > 0** — Step that does async work (small delay). Assert `result.duration` is a number > 0
20. **Completed step captures returned data** — Step returns `{ key: 'value' }`. Assert `result.data` deep equals `{ key: 'value' }`
21. **Skipped step has duration 0** — Assert skipped step `result.duration === 0`

For error tests, use the pattern:

```typescript
try {
  await dag.execute();
  expect.unreachable('should have thrown');
} catch (e) {
  expect(e).toBeInstanceOf(OrchestratorError);
  expect((e as OrchestratorError).code).toBe('EXPECTED_CODE');
}
```

  </action>
  <verify>
Run `npx vitest run src/orchestrator/dag.test.ts` — all tests pass, zero failures.
Run `npx vitest run` — full suite still passes.
  </verify>
  <done>
DAGOrchestrator has 21+ passing tests covering 5 execution shapes (single, linear, diamond, parallel, fan-out), 4 validation errors (cycle x2, missing dep, duplicate id), 6 skip propagation scenarios (direct, fan-out, transitive 3-hop, diamond, independent branch, onSkip callback), 3 event hook tests, and 3 result data tests. New DAGOrchestrator instance per test prevents cross-test pollution.
  </done>
</task>

<task type="auto">
  <name>Task 2: Write TokenUsageTracker tests</name>
  <files>src/context/tracker.test.ts</files>
  <action>
Create `src/context/tracker.test.ts` with comprehensive tests for `TokenUsageTracker`.

**Imports:** `TokenUsageTracker` from `./tracker.js`. Type: `TokenUsage` from `./types.js`.

**Local factory:**

- `mkUsage(round: number, input: number, output: number, budget = 10_000, extras?: Partial<TokenUsage>): TokenUsage` — Returns `{ round, inputTokens: input, outputTokens: output, contextTokens: 0, fileContentTokens: 0, budgetTokens: budget, ...extras }`

**Logger noise suppression:** For tests that exercise the high-utilization warning path (input/budget >= 0.85), use large `budgetTokens` to avoid triggering `logger.warn()` output UNLESS testing the warn path itself. For the explicit warn-path test, this is acceptable — the test validates behavior, not logger output.

**Test scenarios (describe block "TokenUsageTracker"):**

**State transitions (describe "state management"):**

1. **Fresh tracker: zero state** — `getRoundCount() === 0`, `getLastRound() === undefined`, `getTotalUsage()` equals `{ input: 0, output: 0 }`
2. **Single round** — Record 1 round. Assert `getRoundCount() === 1`, `getLastRound()` matches the recorded round, `getTotalUsage()` matches
3. **Three rounds accumulate correctly** — Record 3 rounds with known input/output. Assert `getTotalUsage()` sums correctly (e.g., `{ input: 600, output: 300 }` for 100+200+300 / 50+100+150)
4. **getRoundUsage(n) returns correct round** — Record 2 rounds. Assert `getRoundUsage(1)?.inputTokens === 100`, `getRoundUsage(2)?.inputTokens === 200`
5. **getRoundUsage for nonexistent round** — `getRoundUsage(99)` returns `undefined`
6. **getLastRound after multiple rounds** — 3 rounds. Assert `getLastRound()?.round === 3`

**Cost estimation (describe "estimateCost"):**

7. **Known model (claude-sonnet-4-5): correct formula** — `new TokenUsageTracker(0.85, 'claude-sonnet-4-5')`. `estimateCost(1_000_000, 1_000_000)` should equal `3 + 15 = 18` (inputPerMillion=3, outputPerMillion=15)
8. **Unknown model: falls back to default pricing** — `new TokenUsageTracker(0.85, 'nonexistent-model')`. `estimateCost(1_000_000, 1_000_000)` should equal `15 + 75 = 90` (default pricing)
9. **Zero tokens: cost is 0** — `estimateCost(0, 0)` returns `0`
10. **Cache read tokens contribute at 0.1x rate** — `estimateCost(0, 0, 1_000_000)` for default model. Assert `=== 15 * 0.1 = 1.5` (cache read at 10% of input rate)
11. **Cache creation tokens contribute at 1.25x rate** — `estimateCost(0, 0, 0, 1_000_000)` for default model. Assert `=== 15 * 1.25 = 18.75`
12. **Combined: input + output + cacheRead + cacheCreation** — All four components with known model. Assert sum matches hand-computed value

**Cost aggregation (describe "cost aggregation"):**

13. **getRoundCost for existing round** — Record a round, call `getRoundCost(1)`. Assert matches `estimateCost()` of that round's values
14. **getRoundCost for nonexistent round** — `getRoundCost(99)` returns `0`
15. **getTotalCost across multiple rounds** — Record 2 rounds. Assert `getTotalCost()` equals sum of individual round costs

**Cache savings (describe "getRoundCacheSavings"):**

16. **No cache data: returns null** — Record round without cacheReadTokens. Assert `getRoundCacheSavings(1)` is `null`
17. **With cacheReadTokens: returns savings object** — Record round with `cacheReadTokens: 5000`. Assert result is not null, `tokensSaved === 5000`, `dollarsSaved` and `percentSaved` are positive numbers matching the formula
18. **Nonexistent round: returns null** — `getRoundCacheSavings(99)` is `null`

**Summary formatting (describe "toSummary"):**

19. **No rounds: returns sentinel string** — `toSummary()` returns `'No rounds recorded.'`
20. **Single round: contains round line and total** — Record 1 round. Assert `toSummary()` contains `'Round 1:'` and `'Total:'`
21. **Multiple rounds: contains per-round lines** — Record 3 rounds. Assert output contains `'Round 1:'`, `'Round 2:'`, `'Round 3:'`, and `'Total:'`
22. **Contains budget utilization percentage** — Record round with `inputTokens: 800, budgetTokens: 1000`. Assert summary contains `'80%'`

**Constructor (describe "constructor"):**

23. **Custom warn threshold** — `new TokenUsageTracker(0.5)`. Record round at 60% utilization. Verify the tracker accepted the threshold (no throw). Test the warn path indirectly by checking no crash occurs.
24. **Default model is 'default'** — `new TokenUsageTracker()`. `estimateCost(1_000_000, 1_000_000)` returns `15 + 75 = 90` (default pricing)
    </action>
    <verify>
    Run `npx vitest run src/context/tracker.test.ts` — all tests pass, zero failures.
    Run `npx vitest run` — full suite still passes.
    </verify>
    <done>
    TokenUsageTracker has 24+ passing tests covering state management (fresh/single/multi-round), cost estimation (known model, unknown model, cache read, cache creation, combined), cost aggregation (round cost, total cost), cache savings (null, present, nonexistent round), summary formatting (empty, single, multi-round, utilization percentage), and constructor options. All cost assertions use hand-computed expected values with explicit formula documentation.
    </done>
    </task>

</tasks>

<verification>
1. `npx vitest run src/orchestrator/dag.test.ts` — all DAGOrchestrator tests pass
2. `npx vitest run src/context/tracker.test.ts` — all TokenUsageTracker tests pass
3. `npx vitest run` — full test suite passes with no regressions
4. `npx tsc --noEmit` — no TypeScript errors introduced
</verification>

<success_criteria>

- dag.test.ts contains 21+ passing tests covering 5 execution shapes, 4 validation errors, 6 skip propagation scenarios, 3 event hook tests, and 3 result data tests
- tracker.test.ts contains 24+ passing tests covering state management, cost estimation with formulas, cache savings, summary formatting, and constructor options
- New DAGOrchestrator instance per test (no cross-test pollution)
- No real external service calls — all via injected execute functions and vi.fn()
- Full vitest run and typecheck pass
  </success_criteria>

<output>
After completion, create `.planning/phases/10-algorithm-and-validation-tests/10-02-SUMMARY.md`
</output>

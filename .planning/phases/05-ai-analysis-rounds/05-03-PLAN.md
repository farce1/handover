---
phase: 05-ai-analysis-rounds
plan: 03
type: execute
wave: 3
depends_on: ["05-02"]
files_modified:
  - src/ai-rounds/round-3-features.ts
  - src/ai-rounds/round-4-architecture.ts
  - src/ai-rounds/round-5-edge-cases.ts
  - src/ai-rounds/round-6-deployment.ts
autonomous: true

must_haves:
  truths:
    - "Rounds 3, 5, and 6 declare deps only on ai-round-2, enabling parallel execution in the DAG"
    - "Round 4 depends on ai-round-3, running sequentially after features but parallel with Rounds 5 and 6"
    - "Round 5 fans out per module from Round 2 output, running one LLM call per module via Promise.allSettled"
    - "Each round produces a StepDefinition compatible with the existing DAGOrchestrator"
  artifacts:
    - path: "src/ai-rounds/round-3-features.ts"
      provides: "Round 3 Feature Extraction step creator"
      exports: ["createRound3Step"]
    - path: "src/ai-rounds/round-4-architecture.ts"
      provides: "Round 4 Architecture Detection step creator"
      exports: ["createRound4Step"]
    - path: "src/ai-rounds/round-5-edge-cases.ts"
      provides: "Round 5 Edge Cases & Conventions step creator with per-module fan-out"
      exports: ["createRound5Step"]
    - path: "src/ai-rounds/round-6-deployment.ts"
      provides: "Round 6 Deployment Inference step creator"
      exports: ["createRound6Step"]
  key_links:
    - from: "src/ai-rounds/round-3-features.ts"
      to: "src/orchestrator/step.ts"
      via: "createStep() with deps: ['ai-round-2']"
      pattern: "deps.*ai-round-2"
    - from: "src/ai-rounds/round-4-architecture.ts"
      to: "src/orchestrator/step.ts"
      via: "createStep() with deps: ['ai-round-3']"
      pattern: "deps.*ai-round-3"
    - from: "src/ai-rounds/round-5-edge-cases.ts"
      to: "src/ai-rounds/round-2-modules.ts"
      via: "Reads Round 2 modules for per-module fan-out"
      pattern: "modules.*Round2"
    - from: "src/ai-rounds/round-6-deployment.ts"
      to: "src/orchestrator/step.ts"
      via: "createStep() with deps: ['ai-round-2']"
      pattern: "deps.*ai-round-2"
---

<objective>
Implement Rounds 3-6 (the parallel analysis rounds that run after Round 2) and wire them as DAG steps with correct dependency edges for maximum parallelism.

Purpose: Rounds 3 (features), 5 (edge cases), and 6 (deployment) are independent after Round 2 and run in parallel. Round 4 (architecture) depends on Round 3 for feature context. This dependency graph achieves the 40% speedup requirement (PIPE-02): execution time is max(R3+R4, R5, R6) instead of R3+R4+R5+R6. Round 5 additionally fans out per module (PIPE-03) for parallel per-module analysis.

Output: Four new round implementation files, each exporting a `createRound{N}Step()` function returning a `StepDefinition`.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-ai-analysis-rounds/05-RESEARCH.md
@.planning/phases/05-ai-analysis-rounds/05-01-SUMMARY.md
@.planning/phases/05-ai-analysis-rounds/05-02-SUMMARY.md

@src/ai-rounds/types.ts
@src/ai-rounds/schemas.ts
@src/ai-rounds/prompts.ts
@src/ai-rounds/runner.ts
@src/ai-rounds/validator.ts
@src/ai-rounds/quality.ts
@src/ai-rounds/fallbacks.ts
@src/ai-rounds/round-1-overview.ts
@src/ai-rounds/round-2-modules.ts
@src/providers/base.ts
@src/orchestrator/step.ts
@src/context/packer.ts
@src/analyzers/types.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement Rounds 3 (Features) and 4 (Architecture)</name>
  <files>src/ai-rounds/round-3-features.ts, src/ai-rounds/round-4-architecture.ts</files>
  <action>
**Create `src/ai-rounds/round-3-features.ts`:**

Export `createRound3Step(provider, staticAnalysis, packedContext, config, tracker, estimateTokensFn, getPriorResults)` returning a `StepDefinition`:

- `getPriorResults: () => { round1?: RoundExecutionResult<Round1Output>, round2?: RoundExecutionResult<Round2Output> }`

```typescript
createStep({
  id: 'ai-round-3',
  name: 'AI Round 3: Feature Extraction',
  deps: ['ai-round-2'],  // Runs after R2, parallel with R5 and R6
  execute: async (ctx) => { ... },
  onSkip: () => buildRound3Fallback(staticAnalysis),
})
```

In execute:
1. Gather prior round contexts (Round 1 + Round 2 compressed contexts)
2. Build round-specific data:
   - Module list from Round 2 output (module names, paths, public APIs)
   - Entry points from Round 1 output
   - AST export/import map (which functions are exported, what imports what)
   - Test file mapping (which modules have test coverage)
3. Per locked decision: trace features across modules even when the trace is uncertain. Include this instruction in the prompt.
4. Build prompt with `priorRounds` containing R1 and R2 compressed contexts
5. Call executeRound with Round3OutputSchema
6. Return RoundExecutionResult

**Create `src/ai-rounds/round-4-architecture.ts`:**

Export `createRound4Step(provider, staticAnalysis, packedContext, config, tracker, estimateTokensFn, getPriorResults)` returning a `StepDefinition`:

- `getPriorResults: () => { round1?: RoundExecutionResult<Round1Output>, round2?: RoundExecutionResult<Round2Output>, round3?: RoundExecutionResult<Round3Output> }`

```typescript
createStep({
  id: 'ai-round-4',
  name: 'AI Round 4: Architecture Detection',
  deps: ['ai-round-3'],  // Sequential after R3 (needs feature context), parallel with R5 and R6
  execute: async (ctx) => { ... },
  onSkip: () => buildRound4Fallback(staticAnalysis),
})
```

In execute:
1. Gather prior round contexts (R1 + R2 + R3 compressed contexts)
2. Build round-specific data:
   - Module relationships from Round 2 (dependency graph between modules)
   - Feature cross-module flows from Round 3
   - Import/export patterns from AST data
   - Directory structure suggesting layering (e.g., controllers/, services/, models/)
3. Per locked decision: only state patterns with HIGH confidence. Skip uncertain pattern matches entirely. Include this constraint in the prompt: "Only report architecture patterns you can identify with high confidence based on concrete code evidence. Do not hedge or report uncertain matches."
4. Build prompt with priorRounds containing R1, R2, R3 compressed contexts
5. Call executeRound with Round4OutputSchema
6. Return RoundExecutionResult

Both rounds: use temperature 0.3, maxTokens 4096. On retry, temperature 0.1 with stricter system prompt. Import all shared utilities from plan 01 files.
  </action>
  <verify>Run `npx tsc --noEmit` to verify compilation. Verify Round 3 step deps are `['ai-round-2']` and Round 4 step deps are `['ai-round-3']` by reading the created files.</verify>
  <done>Round 3 traces features across modules with cross-module flows. Round 4 identifies high-confidence architecture patterns only. Dependency graph: R3 after R2, R4 after R3 -- enabling R5 and R6 to run parallel with R3+R4 chain.</done>
</task>

<task type="auto">
  <name>Task 2: Implement Rounds 5 (Edge Cases with per-module fan-out) and 6 (Deployment)</name>
  <files>src/ai-rounds/round-5-edge-cases.ts, src/ai-rounds/round-6-deployment.ts</files>
  <action>
**Create `src/ai-rounds/round-5-edge-cases.ts`:**

Export `createRound5Step(provider, staticAnalysis, packedContext, config, tracker, estimateTokensFn, getPriorResults)` returning a `StepDefinition`:

- `getPriorResults: () => { round1?: RoundExecutionResult<Round1Output>, round2?: RoundExecutionResult<Round2Output> }`

```typescript
createStep({
  id: 'ai-round-5',
  name: 'AI Round 5: Edge Cases & Conventions',
  deps: ['ai-round-2'],  // Only needs R2 modules, parallel with R3/R4/R6
  execute: async (ctx) => { ... },
  onSkip: () => buildRound5Fallback(staticAnalysis),
})
```

**PIPE-03: Per-module fan-out.** In execute:

1. Get Round 2 modules from prior results
2. If no modules (R2 failed/degraded): use top-level directories as module approximation
3. For each module, prepare a per-module analysis:
   a. Filter `staticAnalysis.ast.files` to files within the module's path
   b. Get module-specific TODO items from `staticAnalysis.todos.items`
   c. Get module-specific test files from `staticAnalysis.tests.testFiles`
   d. Build a module-specific prompt using `buildRoundPrompt(5, ROUND_SYSTEM_PROMPTS[5], modulePackedContext, [r2Context], moduleData, estimateTokensFn)`
   e. The packed context for each module should include only files from that module (filter packedContext.files by module path prefix)

4. Fan-out: use `Promise.allSettled()` to run all module analyses in parallel
   - Cap at 20 concurrent module calls (batch in groups of 10 for >20 modules per research recommendation)
   - For each module: call `provider.complete(prompt, Round5ModuleSchema)` directly (NOT through executeRound, since the round-level retry/validation wraps the aggregated result)
   - Track token usage for each module call via tracker

5. Aggregate: collect fulfilled results, log failed modules
   - Build cross-cutting conventions by finding patterns that appear in 2+ modules
   - Combine module findings into Round5Output

6. Run round-level validation on aggregated output via `validateRoundClaims(5, aggregatedOutput, staticAnalysis)`
7. Quality check on aggregated output
8. If >30% drop rate or quality fails AND no retry yet: retry failed modules only (not all modules) with stricter prompting
9. Compress for next round context
10. Return RoundExecutionResult

Per locked decision: Only flag provable issues evidenced in code. No speculative flags. Include in prompt: "Only flag issues you can point to specific evidence in the code. Every edge case MUST cite a file path and ideally a line number. Do not speculate about 'potential' issues."

**Create `src/ai-rounds/round-6-deployment.ts`:**

Export `createRound6Step(provider, staticAnalysis, packedContext, config, tracker, estimateTokensFn, getPriorResults)` returning a `StepDefinition`:

- `getPriorResults: () => { round1?: RoundExecutionResult<Round1Output>, round2?: RoundExecutionResult<Round2Output> }`

```typescript
createStep({
  id: 'ai-round-6',
  name: 'AI Round 6: Deployment Inference',
  deps: ['ai-round-2'],  // Parallel with R3/R4/R5
  execute: async (ctx) => { ... },
  onSkip: () => buildRound6Fallback(staticAnalysis),
})
```

In execute:
1. Gather prior round contexts (R1 + R2 compressed)
2. Build round-specific data focused on deployment signals:
   - Env vars from staticAnalysis.env (env files and references)
   - Dockerfile/docker-compose presence from fileTree.directoryTree
   - CI config files: `.github/workflows/*.yml`, `.gitlab-ci.yml`, `Jenkinsfile`, `.circleci/config.yml` -- check directoryTree for these patterns
   - Package scripts from dependencies.manifests (npm scripts like build, start, deploy, etc.)
   - Infrastructure signals: any files matching `terraform/`, `k8s/`, `helm/`, `serverless.yml`, `vercel.json`, `netlify.toml`
   - Include the actual content of deployment-related files from packedContext if available
3. Per locked decision: best effort always. Include in prompt: "Piece together whatever deployment signals you can find. If evidence is limited, state what you found and what's unclear. Some answer is always better than no answer."
4. Build prompt with priorRounds R1+R2 contexts
5. Call executeRound with Round6OutputSchema
6. maxTokens: 4096 (deployment can be shorter, per research)
7. Return RoundExecutionResult

Both rounds: use temperature 0.3, retry with 0.1. Import shared utilities from plan 01/02 files.
  </action>
  <verify>Run `npx tsc --noEmit` to verify compilation. Verify dependency graph by reading files: R5 deps=['ai-round-2'], R6 deps=['ai-round-2']. Verify R5 uses Promise.allSettled for per-module fan-out.</verify>
  <done>Round 5 fans out per module via Promise.allSettled with only-provable-issues constraint. Round 6 infers deployment from env vars, Dockerfiles, CI configs, and infrastructure files. Both run parallel with R3/R4 after R2 completes. DAG dependency graph enables 40%+ speedup.</done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` passes with no errors
2. Dependency graph:
   - R3: deps=['ai-round-2'] (parallel with R5, R6)
   - R4: deps=['ai-round-3'] (sequential after R3, parallel with R5, R6)
   - R5: deps=['ai-round-2'] (parallel with R3, R4, R6)
   - R6: deps=['ai-round-2'] (parallel with R3, R4, R5)
3. Round 5 uses Promise.allSettled for per-module fan-out
4. Round 5 caps concurrent module calls (batch processing for >20 modules)
5. All rounds produce StepDefinitions compatible with DAGOrchestrator
6. All locked decisions enforced: high-confidence-only for R4, provable-only for R5, best-effort for R6, cross-module tracing for R3
</verification>

<success_criteria>
- All 4 round files compile and export createRound{N}Step functions
- Parallel execution: R3+R5+R6 all depend only on ai-round-2 (40% speedup via DAG)
- R4 depends on ai-round-3 (accumulates R1+R2+R3 context)
- Round 5 per-module fan-out via Promise.allSettled with batching for large projects
- Every round has onSkip fallback, proper error handling, and compressed context output
</success_criteria>

<output>
After completion, create `.planning/phases/05-ai-analysis-rounds/05-03-SUMMARY.md`
</output>

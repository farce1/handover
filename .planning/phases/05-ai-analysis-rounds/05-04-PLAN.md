---
phase: 05-ai-analysis-rounds
plan: 04
type: execute
wave: 4
depends_on: ["05-03"]
files_modified:
  - src/cli/generate.ts
  - src/ai-rounds/summary.ts
autonomous: true

must_haves:
  truths:
    - "generate.ts replaces placeholder AI steps with real Round 1-6 DAG steps using the correct dependency edges"
    - "The DAG has 8 steps total: static-analysis -> ai-round-1 -> ai-round-2 -> [ai-round-3, ai-round-5, ai-round-6] and ai-round-3 -> ai-round-4"
    - "Round results are stored so subsequent rounds can access prior round output"
    - "Pipeline produces a PipelineValidationSummary showing claims validated/corrected per round"
    - "Failed rounds show per-section degraded indicators AND consolidated summary at pipeline end"
  artifacts:
    - path: "src/cli/generate.ts"
      provides: "Updated generate command with real AI round DAG wiring"
      exports: ["runGenerate"]
    - path: "src/ai-rounds/summary.ts"
      provides: "Pipeline validation summary builder and failure report"
      exports: ["buildValidationSummary", "buildFailureReport"]
  key_links:
    - from: "src/cli/generate.ts"
      to: "src/ai-rounds/round-1-overview.ts"
      via: "createRound1Step() call"
      pattern: "createRound1Step"
    - from: "src/cli/generate.ts"
      to: "src/ai-rounds/round-2-modules.ts"
      via: "createRound2Step() call"
      pattern: "createRound2Step"
    - from: "src/cli/generate.ts"
      to: "src/ai-rounds/round-3-features.ts"
      via: "createRound3Step() call"
      pattern: "createRound3Step"
    - from: "src/cli/generate.ts"
      to: "src/orchestrator/dag.ts"
      via: "DAGOrchestrator.addSteps() with all 8 steps"
      pattern: "orchestrator\\.addSteps"
    - from: "src/cli/generate.ts"
      to: "src/providers/factory.ts"
      via: "createProvider() for LLM provider instance"
      pattern: "createProvider"
    - from: "src/cli/generate.ts"
      to: "src/context/packer.ts"
      via: "packFiles() for context packing before rounds"
      pattern: "packFiles"
---

<objective>
Wire all 6 AI rounds into the generate command's DAG pipeline, replacing the placeholder steps, and add the validation summary and failure report.

Purpose: This is the integration plan that brings everything together. The existing generate.ts has placeholder AI steps that log "will run here (Phase 5)". This plan replaces them with real round steps, adds the context packing step, creates the provider instance, wires up result passing between rounds, and adds the validation summary and failure reporting that builds user trust.

Output: Updated generate.ts with the full 8-step DAG (static-analysis, ai-round-1 through ai-round-6, render placeholder). New summary.ts for validation summary and failure report generation.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-ai-analysis-rounds/05-RESEARCH.md
@.planning/phases/05-ai-analysis-rounds/05-01-SUMMARY.md
@.planning/phases/05-ai-analysis-rounds/05-02-SUMMARY.md
@.planning/phases/05-ai-analysis-rounds/05-03-SUMMARY.md

@src/cli/generate.ts
@src/orchestrator/dag.ts
@src/orchestrator/step.ts
@src/providers/base.ts
@src/providers/factory.ts
@src/context/packer.ts
@src/context/scorer.ts
@src/context/tracker.ts
@src/analyzers/coordinator.ts
@src/ai-rounds/round-1-overview.ts
@src/ai-rounds/round-2-modules.ts
@src/ai-rounds/round-3-features.ts
@src/ai-rounds/round-4-architecture.ts
@src/ai-rounds/round-5-edge-cases.ts
@src/ai-rounds/round-6-deployment.ts
@src/ai-rounds/types.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create validation summary and failure report builders</name>
  <files>src/ai-rounds/summary.ts</files>
  <action>
Create `src/ai-rounds/summary.ts`:

Export `buildValidationSummary(roundResults: Map<number, RoundExecutionResult<unknown>>): PipelineValidationSummary`:
- Iterate over roundResults entries
- Accumulate totalClaims, validatedClaims, correctedClaims from each round's validation
- Build roundSummaries array with round number, name (from ROUND_NAMES), status, validated count, corrected count
- For missing rounds (not in map): add entry with status 'skipped' and zero counts
- Return PipelineValidationSummary

Export `buildFailureReport(roundResults: Map<number, RoundExecutionResult<unknown>>): string`:
- Per locked decision: both per-section indicators AND a consolidated summary report
- Build a markdown-formatted failure report listing:
  - Each round: status, if degraded/failed/skipped include the reason
  - Affected documents (map rounds to the documents they feed into -- Round 1 -> overview doc, Round 2 -> module doc, etc.)
  - Validation stats: "X claims validated, Y corrected" per round
- If all rounds succeeded: return a brief "All 6 AI rounds completed successfully. {totalClaims} claims validated, {correctedClaims} corrected."
- If some rounds failed: list them with status and reason, note which downstream documents are affected

Export `formatValidationLine(summary: PipelineValidationSummary): string`:
- One-line summary for terminal output: "AI analysis: 6/6 rounds complete, {validated} claims validated, {corrected} corrected"
- Or: "AI analysis: 4/6 rounds complete (2 degraded), {validated} claims validated, {corrected} corrected"

Import ROUND_NAMES from types.ts, PipelineValidationSummary and RoundExecutionResult from types.ts.
  </action>
  <verify>Run `npx tsc --noEmit` to verify compilation. Run `npx tsx -e "import { buildValidationSummary, formatValidationLine } from './src/ai-rounds/summary.js'; console.log(typeof buildValidationSummary === 'function' ? 'PASS' : 'FAIL')"` to verify exports.</verify>
  <done>Summary builders produce per-round validation stats and consolidated failure report. formatValidationLine provides terminal-friendly one-liner.</done>
</task>

<task type="auto">
  <name>Task 2: Wire all 6 AI rounds into generate.ts DAG pipeline</name>
  <files>src/cli/generate.ts</files>
  <action>
Update `src/cli/generate.ts` to replace placeholder AI steps with real round implementations.

**New imports** (add at top):
- `createRound1Step` from `../ai-rounds/round-1-overview.js`
- `createRound2Step` from `../ai-rounds/round-2-modules.js`
- `createRound3Step` from `../ai-rounds/round-3-features.js`
- `createRound4Step` from `../ai-rounds/round-4-architecture.js`
- `createRound5Step` from `../ai-rounds/round-5-edge-cases.js`
- `createRound6Step` from `../ai-rounds/round-6-deployment.js`
- `buildValidationSummary, formatValidationLine, buildFailureReport` from `../ai-rounds/summary.js`
- `TokenUsageTracker` from `../context/tracker.js`
- `scoreFiles` from `../context/scorer.js`
- `packFiles` from `../context/packer.js`
- `createProvider` from `../providers/factory.js`
- `RoundExecutionResult` type from `../ai-rounds/types.js`

**Modify the DAG pipeline section** (replace the placeholder steps array):

1. After `runStaticAnalysis` completes (in the static-analysis step execute), store the result
2. Create the LLM provider: `const provider = createProvider(config, resolveApiKey(config))`
3. Create the token usage tracker: `const tracker = new TokenUsageTracker()`
4. Create an `estimateTokens` function: `(text: string) => provider.estimateTokens(text)`
5. Store round results in a `Map<number, RoundExecutionResult<unknown>>()` for result passing between rounds

6. After static analysis step completes, run context packing:
   - Score files: `scoreFiles(staticAnalysisResult, config)`
   - Pack files: `packFiles(scoredFiles, astResult, budget, estimateTokensFn)` where budget is computed from provider.maxContextTokens()
   - This can be part of the static-analysis step or a separate 'context-packing' step (prefer folding into static-analysis for simplicity since it's synchronous and fast)

7. Build the steps array with all 8 steps:
   ```
   static-analysis (deps: [])
   ai-round-1 (deps: ['static-analysis']) -- createRound1Step(...)
   ai-round-2 (deps: ['ai-round-1']) -- createRound2Step(...)
   ai-round-3 (deps: ['ai-round-2']) -- createRound3Step(...)
   ai-round-4 (deps: ['ai-round-3']) -- createRound4Step(...)
   ai-round-5 (deps: ['ai-round-2']) -- createRound5Step(...)
   ai-round-6 (deps: ['ai-round-2']) -- createRound6Step(...)
   render (deps: ['ai-round-4', 'ai-round-5', 'ai-round-6']) -- placeholder for Phase 6
   ```

8. For result passing between rounds: each createRound{N}Step receives a `getPriorResults` callback that reads from the roundResults Map. After each round's execute function returns, store the result in the Map. The DAG context (ctx.results) provides step results -- extract the RoundExecutionResult from the step result's data field.

   Approach: Since the DAG orchestrator stores results in `ctx.results`, the getPriorResults callbacks should look up results from the DAG context. But the StepContext is only available inside execute(). Alternative: use a shared mutable Map (roundResults) that each round's execute writes to before returning, and each getPriorResults reads from. This is safe because the DAG guarantees dependency ordering.

9. The render step stays as a placeholder (Phase 6) but now depends on all AI rounds being complete: `deps: ['ai-round-4', 'ai-round-5', 'ai-round-6']`

**After pipeline execution:**

10. Build validation summary: `const summary = buildValidationSummary(roundResults)`
11. Log the validation one-liner: `logger.info(formatValidationLine(summary))`
12. Log token usage summary: `logger.log(tracker.toSummary())`
13. If any rounds are degraded/failed: log the failure report via `logger.warn(buildFailureReport(roundResults))`
14. Remove the "Static analysis pipeline active. AI steps pending Phase 5." message since AI steps are now real
15. Keep the existing static-only mode path unchanged

**Important implementation details:**
- The static-analysis step's execute function should return the StaticAnalysisResult as before, but also trigger context packing. Store the packed context in a local variable accessible to round step creators (via closure).
- The provider is only created when NOT in static-only mode (the existing `resolveApiKey` call already handles this)
- Temperature, retry logic, validation, quality checks are all handled inside each round's step -- generate.ts just wires them together
- The `onStepFail` event handler already logs failures. The failure report at the end provides the consolidated summary (locked decision).
  </action>
  <verify>Run `npx tsc --noEmit` to verify compilation. Run `npx tsx -e "import { runGenerate } from './src/cli/generate.js'; console.log(typeof runGenerate === 'function' ? 'PASS' : 'FAIL')"` to verify the updated generate module exports correctly. Verify that static-only mode still works: check that the early return path is unchanged.</verify>
  <done>generate.ts has 8 DAG steps with correct dependency edges. Rounds 3, 5, 6 run parallel after Round 2. Round 4 runs after Round 3. Results pass between rounds via shared Map. Validation summary and failure report print at pipeline end. Static-only mode unchanged.</done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` passes with no errors
2. DAG has exactly 8 steps with correct dependency edges:
   - static-analysis -> ai-round-1 -> ai-round-2 -> [ai-round-3, ai-round-5, ai-round-6]
   - ai-round-3 -> ai-round-4
   - [ai-round-4, ai-round-5, ai-round-6] -> render
3. Static-only mode (`--static-only`) still works without creating provider or running AI rounds
4. Validation summary prints "X claims validated, Y corrected" after pipeline completion
5. Failed/degraded rounds are listed in the failure report with affected documents
6. Token usage summary prints at pipeline end
7. The render step is still a placeholder (Phase 6 work)
</verification>

<success_criteria>
- generate.ts compiles and exports runGenerate
- Full DAG: 8 steps with correct dependency graph enabling parallel execution (PIPE-02: 40% speedup)
- Round results pass between rounds via shared Map (AI-07: accumulated context)
- Validation summary and failure report match locked decisions (both per-section AND consolidated)
- Static-only mode unaffected
- Token usage tracked and summarized (PIPE-08)
- No new dependencies added
</success_criteria>

<output>
After completion, create `.planning/phases/05-ai-analysis-rounds/05-04-SUMMARY.md`
</output>

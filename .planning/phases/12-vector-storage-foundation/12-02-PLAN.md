---
phase: 12-vector-storage-foundation
plan: 02
type: tdd
wave: 1
depends_on: []
files_modified:
  - src/vector/chunker.ts
  - src/vector/chunker.test.ts
autonomous: true

must_haves:
  truths:
    - 'Markdown documents are split by header hierarchy (#, ##, ###) preserving section structure'
    - 'Chunks stay within 512-token size limit with ~15% overlap between consecutive chunks'
    - 'Code blocks (``` fenced) are never split mid-block'
    - 'Markdown tables are never split mid-table'
    - 'Each chunk carries metadata: source_file, doc_id, doc_type, section_path, h1/h2/h3, chunk_index, token_count, content_preview'
  artifacts:
    - path: 'src/vector/chunker.ts'
      provides: 'Markdown-aware document chunking with header-based splitting and size control'
      exports: ['chunkDocument', 'chunkMarkdown']
    - path: 'src/vector/chunker.test.ts'
      provides: 'TDD tests for chunker covering header splitting, size limits, code block preservation, table preservation, and metadata extraction'
      contains: 'describe'
  key_links:
    - from: 'src/vector/chunker.ts'
      to: 'src/vector/types.ts'
      via: 'imports DocumentChunk and ChunkMetadata types'
      pattern: 'import.*DocumentChunk.*from.*types'
---

<objective>
Implement a markdown-aware document chunker that splits handover's 14 generated markdown documents into retrieval-optimized chunks with rich metadata. Uses TDD to ensure code blocks, tables, and header hierarchy are never broken.

Purpose: Chunking quality directly determines search result quality. A chunk that splits a code block mid-syntax or loses its section context produces poor retrieval results. TDD ensures these invariants hold.

Output: `chunkDocument()` and `chunkMarkdown()` functions with full test coverage.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/12-vector-storage-foundation/12-RESEARCH.md
</context>

<feature>
  <name>Markdown-aware document chunker</name>
  <files>src/vector/chunker.ts, src/vector/chunker.test.ts</files>
  <behavior>
The chunker implements a two-stage hybrid approach (research recommendation):

**Stage 1: Header-based splitting**
Split markdown by headers (#, ##, ###). Each section inherits the header hierarchy as metadata (h1, h2, h3, section_path). Headers are kept in the chunk content (not stripped) for context.

**Stage 2: Size-controlled splitting with structure preservation**
Sections exceeding ~512 tokens (using character/4 estimate per existing BaseProvider pattern) are further split with ~15% overlap (75 tokens). Splitting respects:

- Code block boundaries (``` fenced blocks are atomic — never split mid-block)
- Table boundaries (| rows are atomic — never split mid-table)
- Paragraph boundaries (prefer splitting at double-newlines)
- Line boundaries (fallback)

**Public API:**

`chunkMarkdown(markdown: string, options?: ChunkOptions): TextChunk[]`

- Input: Raw markdown string
- Options: `{ chunkSize?: number; chunkOverlap?: number; }` (defaults: 512 tokens, 75 tokens)
- Output: Array of `TextChunk` = `{ content: string; metadata: { h1?: string; h2?: string; h3?: string; sectionPath: string; } }`

`chunkDocument(content: string, docMeta: { sourceFile: string; docId: string; docType: string; }): DocumentChunk[]`

- Higher-level wrapper that calls `chunkMarkdown` and maps results to `DocumentChunk[]` with full metadata (source_file, doc_id, doc_type, chunk_index, token_count, content_preview)

**Test cases (input -> expected output):**

1. Simple header splitting:
   - Input: `# Title\n\nParagraph 1\n\n## Section A\n\nParagraph 2\n\n## Section B\n\nParagraph 3`
   - Expected: 3 chunks with h1="Title", h2=undefined/Section A/Section B

2. Nested header hierarchy:
   - Input: `# H1\n\n## H2\n\n### H3\n\nContent`
   - Expected: chunk with h1="H1", h2="H2", h3="H3", sectionPath="H1 > H2 > H3"

3. Code block preservation:
   - Input: markdown with a ``` code block (>100 chars)
   - Expected: code block is NOT split across chunks, entire block stays in one chunk

4. Table preservation:
   - Input: markdown with a | table (multi-row)
   - Expected: table is NOT split across rows, entire table stays in one chunk

5. Size splitting with overlap:
   - Input: Large section (>2048 chars, well over 512 tokens)
   - Expected: Multiple chunks, each ~512 tokens, consecutive chunks share ~75 tokens of overlap

6. Metadata completeness:
   - Input: document with sourceFile="03-ARCHITECTURE.md", docId="03-architecture", docType="architecture"
   - Expected: every DocumentChunk has all metadata fields populated, chunk_index is sequential 0-based, content_preview is first 200 chars

7. Empty/minimal input:
   - Input: empty string, single line, no headers
   - Expected: returns 0 or 1 chunk, no crash

8. Frontmatter handling:
   - Input: markdown starting with `---\ntitle: Test\n---\n\n# Content`
   - Expected: YAML frontmatter is stripped or included in first chunk, not treated as header

**Implementation approach (do NOT use LangChain — build lightweight custom splitter):**

Research recommended LangChain, but the dependency adds ~5MB for a function that can be implemented in ~150 lines. The chunking logic is straightforward:

1. Strip YAML frontmatter if present (regex: `/^---\n[\s\S]*?\n---\n/`)
2. Split by header regex (`/^(#{1,3})\s+(.+)$/gm`) — record header level and text
3. For each section: check if content exceeds chunkSize tokens
4. If within limit: emit as single chunk with header metadata
5. If exceeds limit: use recursive splitting with separator priority:
   - First try: split at code block boundaries (`\n```\n`)
   - Then: paragraph boundaries (`\n\n`)
   - Then: line boundaries (`\n`)
   - Last resort: word boundaries (` `)
6. Apply overlap: each subsequent chunk starts `chunkOverlap` tokens before the split point
7. Detect atomic structures (code blocks, tables) — if one exceeds chunk size, emit it as an oversized chunk rather than breaking it

Token estimation: use `Math.ceil(text.length / 4)` (same as BaseProvider.estimateTokens).
</behavior>
<implementation>
After tests are written and failing (RED), implement the chunker following the approach above. The implementation should be pure functions with no side effects — no file I/O, no external dependencies beyond the types from `src/vector/types.ts`.

Key implementation details:

- Use regex for header detection, not a markdown parser (keep it lightweight)
- Track header stack as an array: `[h1, h2, h3]`. When encountering ## after ###, reset h3. When encountering # after ##, reset h2 and h3.
- For code block detection: match opening/closing ``` pairs, track nesting
- For table detection: match consecutive lines starting with |
- Overlap is computed by character count (tokens \* 4 chars/token)
- Each chunk gets a unique sequential chunk_index (0-based within a document)
- content_preview is first 200 characters of chunk content, trimmed
  </implementation>
  </feature>

<verification>
1. `npm test -- src/vector/chunker.test.ts` passes all test cases
2. Code blocks with ``` fences are NEVER split (verified by test)
3. Tables with | rows are NEVER split (verified by test)
4. Chunks stay within expected size limits (verified by test with token count assertion)
5. Header hierarchy metadata is correct (verified by test)
6. Overlap between consecutive chunks exists and is ~15% (verified by test)
</verification>

<success_criteria>

- All 8+ test cases pass
- chunkDocument() produces DocumentChunk[] with complete metadata
- chunkMarkdown() handles edge cases (empty, no headers, nested headers)
- Code blocks and tables are atomic (never split)
- Chunk sizes are within expected range with overlap
- No external dependencies added (pure TypeScript implementation)
  </success_criteria>

<output>
After completion, create `.planning/phases/12-vector-storage-foundation/12-02-SUMMARY.md`
</output>
